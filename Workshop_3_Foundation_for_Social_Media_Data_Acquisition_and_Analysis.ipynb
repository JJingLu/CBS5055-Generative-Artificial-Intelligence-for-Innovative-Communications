{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJingLu/CBS5055-Generative-Artificial-Intelligence-for-Innovative-Communications/blob/main/Workshop_3_Foundation_for_Social_Media_Data_Acquisition_and_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workshop 3: Foundation for Social Media Data Acquisition and Analysis CBS5055\n",
        "\n",
        "**Instructor: Jessie Lu**  \n",
        "\n",
        "Welcome to Workshop 3!  \n",
        "\n",
        "In today‚Äôs session, you will learn the foundational skills for acquiring and analyzing social media-style text data using Python.  \n",
        "\n",
        "The specific dataset we will explore today is **tweet_eval**, originally created by CardiffNLP and published on Hugging Face. It features English Twitter text for seven classic NLP classification tasks, including sentiment analysis, hate speech detection and stance detection, with uniformly formatted train, validation and test splits. This dataset is widely used in social media NLP research, especially for model training and benchmarking on noisy, short user-generated textual content.\n",
        "\n",
        "You can view and explore the dataset directly here:  https://huggingface.co/datasets/cardiffnlp/tweet_eval?utm_source=chatgpt.com"
      ],
      "metadata": {
        "id": "GeFpYLg8wxYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 1: Install & Import Libraries\n",
        "# =================================================\n",
        "\n",
        "# Install necessary Python packages quietly, without verbose output.\n",
        "!pip install datasets pandas matplotlib wordcloud --quiet\n",
        "\n",
        "# Import the load_dataset function from the 'datasets' library.\n",
        "# 'datasets' for loading data from Hugging Face.\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Import the pandas library, aliasing it as 'pd' for convenience.\n",
        "# 'pandas' for data manipulation and analysis.\n",
        "import pandas as pd\n",
        "\n",
        "# Import the matplotlib.pyplot module, aliasing it as 'plt' for convenience.\n",
        "# 'matplotlib' for creating static, interactive, and animated visualizations.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the WordCloud class from the 'wordcloud' library.\n",
        "# 'wordcloud' for generating word cloud images.\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Print a message to confirm that the packages have been successfully installed and imported.\n",
        "print(\"‚úÖ Packages installed and imported\")"
      ],
      "metadata": {
        "id": "p_6nQHcvbXce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 2: Load TweetEval Sentiment Dataset\n",
        "# =================================================\n",
        "\n",
        "# Load the 'tweet_eval' dataset from Hugging Face, specifically the 'sentiment' subset.\n",
        "# The 'load_dataset' function downloads and caches the dataset.\n",
        "dataset = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
        "# Print a header indicating that dataset information will follow.\n",
        "print(\"\\nüì¶ Dataset Info:\")\n",
        "# Print the loaded dataset object, which typically shows its structure (e.g., train, test, validation splits and features).\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "zjDgrzkobaAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 3: Convert to Pandas DataFrame\n",
        "# =================================================\n",
        "\n",
        "# Convert the 'train' split of the loaded dataset into a pandas DataFrame.\n",
        "# This makes it easier to perform data manipulation and analysis using pandas.\n",
        "df_tweets = dataset[\"train\"].to_pandas()\n",
        "\n",
        "# Print a header indicating that a preview of the DataFrame will follow.\n",
        "print(\"\\nüîç First 5 rows preview:\")\n",
        "# Display the first 5 rows of the DataFrame.\n",
        "# 'display()' is used in Colab/Jupyter for rich output.\n",
        "display(df_tweets.head())\n",
        "\n",
        "# Print the shape of the DataFrame (number of rows, number of columns).\n",
        "print(\"\\nüìê Shape (rows, columns):\", df_tweets.shape)\n",
        "# Print a list of all column names in the DataFrame.\n",
        "print(\"üìã Columns:\", df_tweets.columns.tolist())"
      ],
      "metadata": {
        "id": "cVTma355bd2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 4: Understand the Data Structure\n",
        "# =================================================\n",
        "# Columns:\n",
        "# - text: tweet text\n",
        "# - label: sentiment integer (0/1/2)\n",
        "# Print a header indicating that data types will follow.\n",
        "print(\"\\nüß† Data types:\")\n",
        "# Display the data types of each column in the DataFrame.\n",
        "display(df_tweets.dtypes)"
      ],
      "metadata": {
        "id": "dh90IDOjbfm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 5: Map Sentiment Labels to Names\n",
        "# =================================================\n",
        "\n",
        "# Define a dictionary to map numerical sentiment labels to descriptive string names.\n",
        "sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "# Create a new column 'sentiment' in the DataFrame by applying the sentiment_map to the 'label' column.\n",
        "df_tweets[\"sentiment\"] = df_tweets[\"label\"].map(sentiment_map)\n",
        "\n",
        "# Print a header indicating that a preview with sentiment names will follow.\n",
        "print(\"\\nüìÇ With sentiment names:\")\n",
        "# Display the first 5 rows of the DataFrame, showing only the 'text' and the new 'sentiment' columns.\n",
        "display(df_tweets[[\"text\",\"sentiment\"]].head())"
      ],
      "metadata": {
        "id": "Y9Ql1wWMbhOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 6: Sentiment Distribution\n",
        "# =================================================\n",
        "\n",
        "# Print a header indicating that sentiment distribution information will follow.\n",
        "print(\"\\nüìä Sentiment distribution:\")\n",
        "# Calculate the count of each unique value in the 'sentiment' column.\n",
        "# This gives the distribution of negative, neutral, and positive tweets.\n",
        "dist = df_tweets[\"sentiment\"].value_counts()\n",
        "# Display the calculated sentiment distribution.\n",
        "display(dist)\n",
        "\n",
        "# Create a new figure for the plot.\n",
        "plt.figure()\n",
        "# Plot the sentiment distribution as a bar chart.\n",
        "# Assign specific colors to the bars for visual distinction.\n",
        "dist.plot(kind=\"bar\", color=[\"red\",\"gray\",\"green\"])\n",
        "# Set the title of the plot.\n",
        "plt.title(\"Sentiment Distribution in TweetEval ‚Äì Training Set\")\n",
        "# Set the label for the x-axis.\n",
        "plt.xlabel(\"Sentiment\")\n",
        "# Set the label for the y-axis.\n",
        "plt.ylabel(\"Number of Tweets\")\n",
        "# Display the plot.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bl2jIgNJbiuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 7: Word Frequency (All Tweets)\n",
        "# =================================================\n",
        "\n",
        "# Print a header indicating the purpose of this section.\n",
        "print(\"\\nüìà Most common words in all tweets:\")\n",
        "# Calculate the top 10 most common words across all tweets.\n",
        "# .str.lower(): Converts all text to lowercase to treat words like 'The' and 'the' as the same.\n",
        "# .str.split(): Splits each tweet text into a list of words.\n",
        "# .explode(): Transforms each element of a list-like entry to a separate row, creating a Series of individual words.\n",
        "# .value_counts(): Counts the occurrences of each unique word.\n",
        "# .head(10): Selects the top 10 most frequent words.\n",
        "top10 = (\n",
        "    df_tweets[\"text\"]\n",
        "    .str.lower()\n",
        "    .str.split()\n",
        "    .explode()\n",
        "    .value_counts()\n",
        "    .head(10)\n",
        ")\n",
        "# Display the top 10 most common words and their counts.\n",
        "display(top10)"
      ],
      "metadata": {
        "id": "OBcRybhjbmDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 8: Compare Positive vs Negative Language\n",
        "# =================================================\n",
        "\n",
        "# Filter the DataFrame to get text from negative sentiment tweets.\n",
        "neg_text = df_tweets[df_tweets[\"sentiment\"]==\"negative\"][\"text\"]\n",
        "# Filter the DataFrame to get text from positive sentiment tweets.\n",
        "pos_text = df_tweets[df_tweets[\"sentiment\"]==\"positive\"][\"text\"]\n",
        "\n",
        "# Join all words from negative tweets into a single string, handling potential NaN values.\n",
        "neg_words = \" \".join(neg_text.dropna().tolist())\n",
        "# Join all words from positive tweets into a single string, handling potential NaN values.\n",
        "pos_words = \" \".join(pos_text.dropna().tolist())\n",
        "\n",
        "# Generate a word cloud for negative tweets.\n",
        "# Configure width, height, and background color for the word cloud.\n",
        "neg_cloud = WordCloud(width=600, height=300, background_color=\"white\").generate(neg_words)\n",
        "# Generate a word cloud for positive tweets.\n",
        "# Configure width, height, and background color for the word cloud.\n",
        "pos_cloud = WordCloud(width=600, height=300, background_color=\"white\").generate(pos_words)\n",
        "\n",
        "# Create a figure with a specific size for displaying two plots side-by-side.\n",
        "plt.figure(figsize=(10, 4))\n",
        "# Create the first subplot for the negative word cloud.\n",
        "plt.subplot(1, 2, 1)\n",
        "# Display the negative word cloud image; set its title and turn off axis.\n",
        "plt.imshow(neg_cloud); plt.title(\"Negative Tweets Word Cloud\"); plt.axis(\"off\")\n",
        "# Create the second subplot for the positive word cloud.\n",
        "plt.subplot(1, 2, 2)\n",
        "# Display the positive word cloud image; set its title and turn off axis.\n",
        "plt.imshow(pos_cloud); plt.title(\"Positive Tweets Word Cloud\"); plt.axis(\"off\")\n",
        "# Show the plots.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7M9xTHUYbnno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================\n",
        "# Part 9: Show Sample Tweets by Sentiment\n",
        "# =================================================\n",
        "\n",
        "def show_samples(sentiment, n=3):\n",
        "    # Print a header indicating the sentiment for the samples.\n",
        "    print(f\"\\nüìç {sentiment.upper()} tweet samples:\")\n",
        "    # Filter the DataFrame to get tweets of the specified sentiment and randomly sample 'n' of them.\n",
        "    samples = df_tweets[df_tweets[\"sentiment\"] == sentiment].sample(n)\n",
        "    # Iterate through the sampled tweets and print their text.\n",
        "    for i, row in samples.iterrows():\n",
        "        print(\"‚Äî\"*60)\n",
        "        print(row[\"text\"])\n",
        "\n",
        "# Call the function to display sample negative tweets.\n",
        "show_samples(\"negative\")\n",
        "# Call the function to display sample positive tweets.\n",
        "show_samples(\"positive\")"
      ],
      "metadata": {
        "id": "6qpHGaFabpbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}