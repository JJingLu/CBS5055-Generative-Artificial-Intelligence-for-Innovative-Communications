{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJingLu/CBS5055-Generative-Artificial-Intelligence-for-Innovative-Communications/blob/main/Workshop_4_Generative_AI_for_Advanced_Text_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20v_766-6ZdM"
      },
      "source": [
        "## Workshop 4: Generative AI for Advanced Text Analysis CBS5055\n",
        "\n",
        "**Instructor: Jessie Lu**  \n",
        "\n",
        "Welcome to Workshop 4!  \n",
        "\n",
        "In today’s session, you will learn the efficient fine-tuning technique called LoRA, enabling the model to better adapt to your data. You will get hands-on experience applying the fine-tuned model to real data for sentiment analysis, and you will learn how to interpret the analysis results.\n",
        "\n",
        "\n",
        "\n",
        "The specific dataset we will explore today is **go_emotions** , originally created by Google Research and published on Hugging Face. It contains approximately 58,000 Reddit comments, each annotated (by human raters) with one or more of 28 fine-grained emotion categories. This dataset is widely used in emotion detection, affective computing, and social media analysis research.  \n",
        "\n",
        "You can view and explore the dataset directly here:  \n",
        "*https://huggingface.co/datasets/google-research-datasets/go_emotions*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MOIzp2y6T1p"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Required Libraries\n",
        "!pip install -q \\\n",
        "    transformers>=4.30.0 \\\n",
        "    datasets>=2.12.0 \\\n",
        "    peft>=0.4.0 \\\n",
        "    tqdm>=4.65.0 \\\n",
        "    scikit-learn>=1.2.2 \\\n",
        "    torch>=2.0.0 \\\n",
        "    matplotlib>=3.7.0 \\\n",
        "    seaborn>=0.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_GflmU26VKc"
      },
      "outputs": [],
      "source": [
        "#@title 2. Import Libraries\n",
        "from datasets import load_dataset # Import function to load datasets\n",
        "from transformers import (\n",
        "    DistilBertTokenizer, # Import tokenizer for DistilBERT\n",
        "    DistilBertForSequenceClassification, # Import DistilBERT model for sequence classification\n",
        "    get_linear_schedule_with_warmup # Import learning rate scheduler\n",
        ")\n",
        "from torch.optim import AdamW # Import AdamW optimizer\n",
        "from peft import get_peft_model, LoraConfig, TaskType # Import PEFT utilities for LoRA\n",
        "from tqdm.auto import tqdm # Import tqdm for progress bars\n",
        "import torch # Import PyTorch library\n",
        "from torch.nn.utils import clip_grad_norm_ # Import gradient clipping utility\n",
        "from sklearn.metrics import accuracy_score # Import accuracy metric from scikit-learn\n",
        "from torch.utils.data import DataLoader # Import DataLoader for batching data\n",
        "import os # Import os module for interacting with the operating system\n",
        "from pathlib import Path # Import Path for object-oriented filesystem paths\n",
        "import matplotlib.pyplot as plt # Import matplotlib for plotting\n",
        "import seaborn as sns # Import seaborn for enhanced data visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-t7CtY87Mk7"
      },
      "outputs": [],
      "source": [
        "#@title 3. Directory Setup\n",
        "SAVE_DIR = Path(\"saved_data\") # Define the base directory for saving data\n",
        "MODEL_DIR = SAVE_DIR / \"model\" # Define the directory for saving models\n",
        "DATASET_DIR = SAVE_DIR / \"dataset\" # Define the directory for saving datasets\n",
        "TOKENIZED_DIR = SAVE_DIR / \"tokenized_dataset\" # Define the directory for saving tokenized datasets\n",
        "LORA_DIR = MODEL_DIR / \"trained_LoRA\" # Define the directory for saving trained LoRA models\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True) # Create the base save directory if it doesn't exist\n",
        "os.makedirs(MODEL_DIR, exist_ok=True) # Create the model save directory if it doesn't exist\n",
        "os.makedirs(DATASET_DIR, exist_ok=True) # Create the dataset save directory if it doesn't exist\n",
        "os.makedirs(TOKENIZED_DIR, exist_ok=True) # Create the tokenized dataset save directory if it doesn't exist\n",
        "os.makedirs(LORA_DIR, exist_ok=True) # Create the LoRA model save directory if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGGxwqpF7PaI"
      },
      "outputs": [],
      "source": [
        "#@title 4. Load Dataset\n",
        "dataset_path = DATASET_DIR / \"go_emotions_simplified\" # Define the path for the simplified go_emotions dataset\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"Loading cached dataset...\") # Inform the user that a cached dataset is being loaded\n",
        "    dataset = load_dataset(\"go_emotions\", \"simplified\", cache_dir=str(dataset_path)) # Load dataset from cache\n",
        "else:\n",
        "    print(\"Downloading dataset...\") # Inform the user that the dataset is being downloaded\n",
        "    dataset = load_dataset(\"go_emotions\", \"simplified\") # Download the go_emotions dataset\n",
        "    dataset.save_to_disk(str(dataset_path)) # Save the downloaded dataset to disk\n",
        "\n",
        "# Get number of unique labels\n",
        "num_labels = len(set(label for example in dataset['train'] for label in example['labels'])) # Calculate the number of unique emotion labels\n",
        "print(f\"Number of emotion labels: {num_labels}\") # Print the total number of unique emotion labels\n",
        "\n",
        "# Define emotion mapping\n",
        "EMOTIONS = [\n",
        "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
        "    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
        "    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
        "    \"joy\", \"love\", \"nervousness\", \"neutral\", \"optimism\", \"pride\", \"realization\",\n",
        "    \"relief\", \"remorse\", \"sadness\", \"surprise\"\n",
        "] # Define a list of 28 fine-grained emotion categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHojc5l37R75"
      },
      "outputs": [],
      "source": [
        "#@title 5. Initialize Model and Tokenizer\n",
        "from peft import PeftModel, PeftConfig # Import PeftModel and PeftConfig\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\") # Load the pre-trained DistilBERT tokenizer\n",
        "\n",
        "# Initialize or load the model\n",
        "model_path = LORA_DIR / \"distilbert_lora_go_emotions\" # Define the path where the LoRA model might be saved\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"Loading saved LoRA adapter...\") # Inform user that a saved LoRA adapter is being loaded\n",
        "    # Load the base model first\n",
        "    base_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\", # Load the pre-trained DistilBERT base model\n",
        "        num_labels=num_labels, # Initialize model with the correct number of labels\n",
        "        problem_type=\"multi_label_classification\" # Explicitly set for multi-label\n",
        "    )\n",
        "    # Load the LoRA adapter on top of the base model\n",
        "    model = PeftModel.from_pretrained(base_model, str(model_path))\n",
        "else:\n",
        "    print(\"Initializing new model without LoRA...\") # Inform user that a new model is being initialized\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\", # Load the pre-trained DistilBERT base model\n",
        "        num_labels=num_labels, # Initialize model with the correct number of labels\n",
        "        problem_type=\"multi_label_classification\" # Explicitly set for multi-label\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcqpduRQ7UVc"
      },
      "outputs": [],
      "source": [
        "#@title 6. Configure and Apply LoRA\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS, # Define the task type as Sequence Classification\n",
        "    r=8, # Set the LoRA attention dimension (rank)\n",
        "    lora_alpha=32, # Set the scaling factor for LoRA weights\n",
        "    lora_dropout=0.1, # Set the dropout probability for LoRA layers\n",
        "    bias=\"none\", # Specify that no bias will be trained\n",
        "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"] # Specify the modules to apply LoRA to\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config) # Apply the LoRA configuration to the model\n",
        "model.print_trainable_parameters() # Print the number of trainable parameters after applying LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3g-YH6S7WZj"
      },
      "outputs": [],
      "source": [
        "#@title 7. Data Preprocessing\n",
        "def tokenize_function(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples['text'], # Input text to the tokenizer\n",
        "        padding='max_length', # Pad sequences to the maximum length\n",
        "        truncation=True, # Truncate sequences longer than max_length\n",
        "        max_length=64, # Set the maximum sequence length\n",
        "        return_tensors=None # Return Python lists/arrays, not PyTorch tensors yet\n",
        "    )\n",
        "\n",
        "    # Handle labels (one-hot encode for multi-label classification)\n",
        "    batch_one_hot_labels = []\n",
        "    for labels_list_for_one_example in examples['labels']:\n",
        "        one_hot_labels = [0.0] * num_labels\n",
        "        for label_id in labels_list_for_one_example:\n",
        "            if 0 <= label_id < num_labels:\n",
        "                one_hot_labels[label_id] = 1.0\n",
        "        batch_one_hot_labels.append(one_hot_labels)\n",
        "    tokenized_inputs['labels'] = batch_one_hot_labels\n",
        "    return tokenized_inputs # Return the tokenized example with labels\n",
        "\n",
        "batch_size = 64 # Define the batch size for data loaders\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_path = TOKENIZED_DIR / \"tokenized_dataset\" # Define the path for saving tokenized dataset\n",
        "if os.path.exists(tokenized_path):\n",
        "    print(\"Loading cached tokenized dataset...\") # Inform user that a cached dataset is being loaded\n",
        "    tokenized_dataset = load_dataset(\"go_emotions\", \"simplified\", cache_dir=str(tokenized_path)) # Load tokenized dataset from cache\n",
        "    # Re-tokenize as the previous save might not be in the right format\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True, batch_size=batch_size*4, remove_columns=dataset[\"train\"].column_names, num_proc=1) # Apply tokenization function to the dataset again\n",
        "else:\n",
        "    print(\"Tokenizing dataset...\") # Inform user that the dataset is being tokenized\n",
        "    tokenized_dataset = dataset.map(\n",
        "        tokenize_function, # Apply the tokenization function\n",
        "        batched=True, # Process examples in batches\n",
        "        batch_size=batch_size * 4, # Set batch size for map function\n",
        "        remove_columns=dataset[\"train\"].column_names, # Remove original text and labels columns\n",
        "        num_proc=1 # Use a single process to prevent potential hangs\n",
        "    )\n",
        "    tokenized_dataset.save_to_disk(str(tokenized_path)) # Save the tokenized dataset to disk\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]) # Convert dataset columns to PyTorch tensors\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(tokenized_dataset[\"train\"], batch_size=batch_size, shuffle=True) # Create a DataLoader for the training set\n",
        "eval_loader = DataLoader(tokenized_dataset[\"validation\"], batch_size=batch_size) # Create a DataLoader for the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjKSzilZ7ZWr"
      },
      "outputs": [],
      "source": [
        "#@title 8. Train the Model\n",
        "# Setup\n",
        "import torch.cuda.amp as amp # Import Automatic Mixed Precision utilities\n",
        "scaler = amp.GradScaler() # Initialize a gradient scaler for mixed precision training\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # Determine if CUDA (GPU) is available, otherwise use CPU\n",
        "print(f\"Using device: {device}\") # Confirm which device is being used\n",
        "model.to(device) # Move the model to the selected device\n",
        "optimizer = AdamW(model.parameters(), lr=4e-5) # Initialize the AdamW optimizer with a learning rate\n",
        "max_grad_norm = 1.0 # Define the maximum gradient norm for clipping\n",
        "num_epochs = 3 # Set the number of training epochs\n",
        "\n",
        "num_training_steps = len(train_loader) * num_epochs # Calculate the total number of training steps\n",
        "num_warmup_steps = num_training_steps // 10 # Calculate the number of warmup steps for the scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps) # Initialize the learning rate scheduler\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode\n",
        "    epoch_loss = 0 # Initialize loss for the current epoch\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\") # Create a progress bar for the training loader\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()} # Move batch tensors to the appropriate device\n",
        "        # Explicitly cast labels to float32 for BCEWithLogitsLoss\n",
        "        batch['labels'] = batch['labels'].to(torch.float32)\n",
        "        optimizer.zero_grad() # Reset gradients for the current iteration (moved before forward pass for mixed precision)\n",
        "\n",
        "        with amp.autocast(enabled=device.type == 'cuda'): # Enable automatic mixed precision only if CUDA is available\n",
        "            outputs = model(**batch) # Perform a forward pass\n",
        "            loss = outputs.loss # Get the loss from the model outputs\n",
        "\n",
        "        scaler.scale(loss).backward() # Scale loss and perform backpropagation\n",
        "        scaler.unscale_(optimizer) # Unscale gradients before clipping\n",
        "        clip_grad_norm_(model.parameters(), max_grad_norm) # Clip gradients to prevent exploding gradients\n",
        "        scaler.step(optimizer) # Update model parameters using the scaled gradients\n",
        "        scaler.update() # Update the scale for the next iteration\n",
        "        scheduler.step() # Update the learning rate scheduler\n",
        "\n",
        "        epoch_loss += loss.item() # Accumulate the loss for the epoch\n",
        "        progress_bar.set_postfix({\"loss\": f\"{epoch_loss/(progress_bar.n+1):.4f}\"}) # Update the progress bar with current average loss\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader) # Calculate the average loss for the epoch\n",
        "    print(f\"Epoch {epoch+1} Average Loss: {avg_loss:.4f}\") # Print the average loss for the epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDvAQN7c7bve"
      },
      "outputs": [],
      "source": [
        "#@title 9. Evaluate the Model\n",
        "# Before running this cell, please ensure that cells 5, 6, and 8 have been executed successfully.\n",
        "\n",
        "from sklearn.metrics import accuracy_score # Import accuracy metric from scikit-learn\n",
        "import torch # Ensure torch is imported for tensor operations\n",
        "\n",
        "# Ensure the model is on the correct device before evaluation\n",
        "model.to(device)\n",
        "model.eval() # Set the model to evaluation mode\n",
        "all_predictions = [] # Initialize a list to store all model predictions\n",
        "all_labels = [] # Initialize a list to store all true labels\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculations for inference\n",
        "    for batch in tqdm(eval_loader, desc=\"Evaluating\"): # Iterate over the evaluation data loader with a progress bar\n",
        "        batch = {k: v.to(device) for k, v in batch.items()} # Move batch tensors to the appropriate device (CPU/GPU)\n",
        "        # Explicitly cast labels to float32 for BCEWithLogitsLoss\n",
        "        batch['labels'] = batch['labels'].to(torch.float32)\n",
        "        outputs = model(**batch) # Perform a forward pass to get model outputs\n",
        "\n",
        "        # For multi-label classification, apply sigmoid and threshold to get binary predictions\n",
        "        probabilities = torch.sigmoid(outputs.logits) # Get probabilities for each class\n",
        "        predictions = (probabilities > 0.5).int() # Convert probabilities to binary (0 or 1) based on a 0.5 threshold\n",
        "\n",
        "        all_predictions.extend(predictions.cpu().numpy()) # Store predictions, moving them to CPU and converting to NumPy array\n",
        "        all_labels.extend(batch['labels'].cpu().numpy()) # Store true labels, moving them to CPU and converting to NumPy array\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_predictions) # Calculate the accuracy score (subset accuracy for multi-label)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\") # Print the calculated validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxlc0rXo7dxl"
      },
      "outputs": [],
      "source": [
        "#@title 10. Model Prediction\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\").to(device) # Tokenize the input text and move to device\n",
        "    with torch.no_grad(): # Disable gradient calculations for inference\n",
        "        outputs = model(**inputs) # Get model outputs (logits)\n",
        "        # For multi-label classification, apply sigmoid and threshold\n",
        "        probabilities = torch.sigmoid(outputs.logits) # Get probabilities for each class\n",
        "        predictions = (probabilities > 0.5).int() # Convert probabilities to binary (0 or 1) based on a 0.5 threshold\n",
        "\n",
        "    # Convert predictions to a list of emotion names\n",
        "    predicted_emotions = [EMOTIONS[idx] for idx, val in enumerate(predictions[0]) if val == 1]\n",
        "\n",
        "    if not predicted_emotions:\n",
        "        return \"neutral\" # Return 'neutral' if no emotion is predicted above the threshold\n",
        "    return \", \".join(predicted_emotions) # Return a comma-separated string of predicted emotions\n",
        "\n",
        "# Test with examples\n",
        "examples = [\n",
        "    \"I'm so excited about this workshop!\",\n",
        "    \"This is the worst experience ever.\",\n",
        "    \"The meeting is scheduled for 3 PM.\",\n",
        "    \"Thank you for your help!\",\n",
        "    \"I love spending time with my family.\"\n",
        "]\n",
        "\n",
        "for text in examples:\n",
        "    print(f\"Text: {text}\") # Print the input text\n",
        "    print(f\"Predicted Emotion: {predict_sentiment(text)}\\n\") # Print the predicted emotion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 11. Visualization: Emotion Distribution in Training Data\n",
        "\n",
        "df = dataset[\"train\"].to_pandas() # Convert the training dataset to a pandas DataFrame\n",
        "df[\"emotion\"] = df[\"labels\"].apply(lambda x: EMOTIONS[x[0]] if len(x) > 0 else \"neutral\") # Map numerical labels to emotion names, handling empty lists explicitly\n",
        "emotion_counts = df[\"emotion\"].value_counts().head(10) # Get the top 10 most common emotions and their counts\n",
        "\n",
        "plt.figure(figsize=(12, 6)) # Create a new figure with a specified size\n",
        "sns.barplot(x=emotion_counts.values, y=emotion_counts.index, palette=\"viridis\") # Create a bar plot of emotion counts\n",
        "plt.title(\"Top 10 Most Common Emotions in GoEmotions Dataset\") # Set the title of the plot\n",
        "plt.xlabel(\"Number of Comments\") # Set the label for the x-axis\n",
        "plt.ylabel(\"Emotion\") # Set the label for the y-axis\n",
        "plt.show() # Display the plot"
      ],
      "metadata": {
        "id": "Qu3qZSnyiNii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W_RE7cZ7gz6"
      },
      "outputs": [],
      "source": [
        "#@title 12. Save the Model\n",
        "model.save_pretrained(str(LORA_DIR / \"distilbert_lora_go_emotions\")) # Save the trained LoRA model to the specified directory\n",
        "tokenizer.save_pretrained(str(LORA_DIR / \"distilbert_lora_go_emotions\")) # Save the tokenizer to the same directory\n",
        "print(\"Model and tokenizer saved successfully!\") # Print a success message"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 13. Social media engagement analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
        "from collections import Counter\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ====================== Step 1: Load and Preprocess facebook_engagement_data Dataset ======================\n",
        "# Load dataset (stable and available without extra permissions)\n",
        "dataset = load_dataset(\"Falah/facebook_engagement_data\", split=\"train\")\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "# 1. Standardize core fields (align analysis logic)\n",
        "df = df.rename(columns={\n",
        "    'engagement_reaction_count': 'like_count',  # Likes/Reactions (corresponds to like)\n",
        "    'engagement_comment_count': 'comment_count',  # Comment count\n",
        "    'engagement_share_count': 'share_count',  # Share count (corresponds to retweet)\n",
        "    'url_to_image': 'image_url'  # Image link (to determine if media is present)\n",
        "})\n",
        "\n",
        "# 2. Construct key features (optimization: relax text length filtering)\n",
        "df['text'] = df['title'] + \" \" + df['content'].fillna(\"\")  # Combine title + body as analysis text\n",
        "df['has_media'] = df['image_url'].notna()  # Boolean: whether it contains an image (True=has media)\n",
        "df['total_engagement'] = df['like_count'] + df['comment_count'] + df['share_count']  # Total engagement count\n",
        "\n",
        "# 3. Data Cleaning (optimization: reduce filtering, retain more samples)\n",
        "for col in ['like_count', 'comment_count', 'share_count', 'total_engagement']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "df = df[df['text'].str.len() > 1]  # Only filter out empty text (no longer filtering short text)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Print data volume monitoring\n",
        "print(f\"✅ Dataset loaded: {len(df)} valid records\")\n",
        "print(f\"Records with media: {df['has_media'].sum()} | Records without media: {len(df) - df['has_media'].sum()}\")\n",
        "print(f\"Average likes: {df['like_count'].mean():.2f} | Average shares: {df['share_count'].mean():.2f}\")\n",
        "\n",
        "# ====================== Step 2: Perform Text Sentiment Annotation with Twitter-specific Sentiment Model ======================\n",
        "# Load cardiffnlp/twitter-xlm-roberta-base-sentiment (adapted for social media text)\n",
        "MODEL = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "config = AutoConfig.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "\n",
        "# Text preprocessing (adapted to model requirements: replace @users and links)\n",
        "def preprocess_text(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Batch sentiment annotation (returns positive/neutral/negative labels)\n",
        "def get_sentiment(text):\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=128)\n",
        "    output = model(**encoded_input)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = np.exp(scores) / np.sum(np.exp(scores))  # Softmax normalization\n",
        "    ranking = np.argsort(scores)[::-1]\n",
        "    return config.id2label[ranking[0]]  # Return the sentiment label with the highest confidence\n",
        "\n",
        "# Optimization: use more samples (first 2000), avoid insufficient samples\n",
        "sample_df = df.head(2000).copy()\n",
        "sample_df['sentiment'] = sample_df['clean_text'].apply(get_sentiment)\n",
        "\n",
        "# Print annotated sample distribution\n",
        "print(f\"\\n=== Sentiment Label Distribution ===\")\n",
        "print(sample_df['sentiment'].value_counts())\n",
        "print(f\"Number of valid annotated samples: {len(sample_df)}\")\n",
        "\n",
        "# ====================== Step 3: Core Correlation Analysis (Content Features → Engagement) ======================\n",
        "# 3.1 Relationship between sentiment labels and engagement metrics (group statistics)\n",
        "sentiment_engage = sample_df.groupby('sentiment').agg({\n",
        "    'like_count': ['mean', 'median'],\n",
        "    'comment_count': ['mean', 'median'],\n",
        "    'share_count': ['mean', 'median'],\n",
        "    'total_engagement': ['mean', 'median']\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\n=== Sentiment Labels vs Engagement Metrics ===\")\n",
        "print(sentiment_engage)\n",
        "\n",
        "# 3.2 Relationship between media features and engagement metrics\n",
        "media_engage = sample_df.groupby('has_media').agg({\n",
        "    'like_count': 'mean',\n",
        "    'share_count': 'mean',\n",
        "    'total_engagement': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\n=== Has Media vs Average Engagement ===\")\n",
        "print(media_engage)\n",
        "\n",
        "# 3.3 Correlation Analysis (optimization: add sample count validation + error handling)\n",
        "# Encode categorical variables\n",
        "sample_df['sentiment_code'] = sample_df['sentiment'].map({'positive': 2, 'neutral': 1, 'negative': 0})\n",
        "sample_df['has_media_code'] = sample_df['has_media'].astype(int)\n",
        "\n",
        "# Filter valid data\n",
        "valid_data = sample_df.dropna(subset=['sentiment_code', 'total_engagement', 'has_media_code'])\n",
        "print(f\"\\n=== Correlation Analysis Preparation ===\")\n",
        "print(f\"Number of valid samples for analysis: {len(valid_data)}\")\n",
        "\n",
        "# Core fix: add sample count check\n",
        "if len(valid_data) >= 2:\n",
        "    # Check if variables have more than one unique value (to avoid meaningless correlation calculation)\n",
        "    if valid_data['sentiment_code'].nunique() > 1:\n",
        "        corr_senti_total, p_senti = pearsonr(valid_data['sentiment_code'], valid_data['total_engagement'])\n",
        "        print(f\"Correlation between sentiment label and total engagement: {corr_senti_total:.4f} (p-value: {p_senti:.4f})\")\n",
        "    else:\n",
        "        print(\"⚠️ Sentiment label has only one value, correlation cannot be calculated\")\n",
        "        corr_senti_total, p_senti = np.nan, np.nan\n",
        "\n",
        "    if valid_data['has_media_code'].nunique() > 1:\n",
        "        corr_media_total, p_media = pearsonr(valid_data['has_media_code'], valid_data['total_engagement'])\n",
        "        print(f\"Correlation between media feature and total engagement: {corr_media_total:.4f} (p-value: {p_media:.4f})\")\n",
        "    else:\n",
        "        print(\"⚠️ Media feature has only one value, correlation cannot be calculated\")\n",
        "        corr_media_total, p_media = np.nan, np.nan\n",
        "else:\n",
        "    print(\"⚠️ Insufficient valid samples (less than 2), skipping correlation calculation\")\n",
        "    corr_senti_total, p_senti = np.nan, np.nan\n",
        "    corr_media_total, p_media = np.nan, np.nan\n",
        "\n",
        "# 3.4 Association between high-frequency words and engagement (text feature level)\n",
        "def clean_text_for_wordcount(text):\n",
        "    \"\"\"Clean text for word frequency counting\"\"\"\n",
        "    text = re.sub(r'@user|http|[^\\w\\s]', '', text.lower())  # Remove special characters, lowercase\n",
        "    # Extend stopwords list to improve word frequency quality\n",
        "    stopwords = ['the', 'and', 'for', 'with', 'to', 'of', 'a', 'in', 'is', 'it', 'on', 'at', 'by', 'from']\n",
        "    return [word for word in text.split() if len(word) > 2 and word not in stopwords]  # Filter stopwords\n",
        "\n",
        "# Count high-frequency words under different sentiments (associated with high engagement)\n",
        "high_engage_threshold = sample_df['total_engagement'].quantile(0.7)  # Top 30% are high engagement\n",
        "high_engage_df = sample_df[sample_df['total_engagement'] > high_engage_threshold]\n",
        "\n",
        "print(f\"\\n=== High Engagement Text Analysis ===\")\n",
        "print(f\"High engagement threshold: {high_engage_threshold:.2f} | Number of high engagement samples: {len(high_engage_df)}\")\n",
        "\n",
        "if len(high_engage_df) > 0:\n",
        "    emotion_high_words = {}\n",
        "    for emotion in high_engage_df['sentiment'].unique():\n",
        "        texts = high_engage_df[high_engage_df['sentiment'] == emotion]['clean_text'].apply(clean_text_for_wordcount)\n",
        "        all_words = [word for sublist in texts for word in sublist]\n",
        "        emotion_high_words[emotion] = Counter(all_words).most_common(8)\n",
        "\n",
        "    print(\"\\n=== High-frequency words in high engagement texts for each sentiment (top 8) ===\")\n",
        "    for emotion, words in emotion_high_words.items():\n",
        "        print(f\"{emotion}: {words}\")\n",
        "else:\n",
        "    print(\"⚠️ No high engagement text samples, skipping word frequency analysis\")\n",
        "\n",
        "# ====================== Step 4: Visualize Analysis Results (Academic Quality Plots) ======================\n",
        "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 4.1 Comparison of total engagement across different sentiments (bar chart)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='sentiment', y='total_engagement', data=sample_df, palette='Set2')\n",
        "plt.title('Sentiment vs Total Engagement (Facebook Data)', fontsize=14, pad=20)\n",
        "plt.xlabel('Sentiment Label', fontsize=12)\n",
        "plt.ylabel('Average Total Engagement (Like+Comment+Share)', fontsize=12)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('facebook_sentiment_engagement.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 4.2 Engagement metric correlation heatmap (optimization: handle NaN values)\n",
        "corr_cols = ['like_count', 'comment_count', 'share_count', 'total_engagement', 'sentiment_code', 'has_media_code']\n",
        "corr_matrix = sample_df[corr_cols].corr().round(3)\n",
        "# Fill NaN values with 0 (to prevent heatmap errors)\n",
        "corr_matrix = corr_matrix.fillna(0)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.3f')\n",
        "plt.title('Correlation Matrix of Engagement Metrics & Features', fontsize=14, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('facebook_correlation_heatmap.png', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3nOiXCBxy4vh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/D0dwd9Hdr1Y4g06kbhVg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}